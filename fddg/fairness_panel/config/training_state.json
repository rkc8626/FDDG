{
  "batch_size": 64,
  "learning_rate": 0.001,
  "epoch": 4,
  "stdout": "2025-04-01 03:51:26.746498: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1743493886.764484 1244981 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1743493886.770096 1244981 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-04-01 03:51:26.788450: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n/orange/ufdatastudios/chenz1/TBtest/YOLOX/yolox/core/trainer.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(enabled=args.fp16)\n2025-04-01 03:51:30 | INFO     | yolox.core.trainer:132 - Dynamic configuration enabled\n2025-04-01 03:51:30 | INFO     | yolox.core.trainer:133 - Config path: /home/chenz1/toorange/TBtest/YOLOX/fairness_panel/config/config.json\n2025-04-01 03:51:30 | INFO     | yolox.core.trainer:134 - State path: /home/chenz1/toorange/TBtest/YOLOX/fairness_panel/config/training_state.json\n2025-04-01 03:51:30 | INFO     | yolox.core.trainer:217 - args: Namespace(experiment_name='my_yolox_gender', name=None, dist_backend='nccl', dist_url=None, batch_size=64, devices=1, exp_file='/home/chenz1/toorange/TBtest/YOLOX/exps/example/custom/my_yolox_gender.py', resume=False, ckpt=None, start_epoch=None, num_machines=1, machine_rank=0, fp16=True, cache=None, occupy=False, logger='tensorboard', opts=[])\n2025-04-01 03:51:30 | INFO     | yolox.core.trainer:218 - exp value:\n\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 keys              \u2502 values                                 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 seed              \u2502 None                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 output_dir        \u2502 './YOLOX_outputs'                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 print_interval    \u2502 10                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 eval_interval     \u2502 1                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dataset           \u2502 None                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 num_classes       \u2502 2                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 depth             \u2502 0.33                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 width             \u2502 0.5                                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 act               \u2502 'silu'                                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 data_num_workers  \u2502 4                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 input_size        \u2502 (640, 640)                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 multiscale_range  \u2502 5                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 data_dir          \u2502 '/home/chenz1/toorange/TBtest/dataset' \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 train_ann         \u2502 'train.json'                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 val_ann           \u2502 'val.json'                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 test_ann          \u2502 'instances_test2017.json'              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 mosaic_prob       \u2502 1.0                                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 mixup_prob        \u2502 1.0                                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 hsv_prob          \u2502 1.0                                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 flip_prob         \u2502 0.5                                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 degrees           \u2502 10.0                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 translate         \u2502 0.1                                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 mosaic_scale      \u2502 (0.1, 2)                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 enable_mixup      \u2502 True                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 mixup_scale       \u2502 (0.5, 1.5)                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 shear             \u2502 2.0                                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 warmup_epochs     \u2502 5                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 max_epoch         \u2502 300                                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 warmup_lr         \u2502 0                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 min_lr_ratio      \u2502 0.05                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 basic_lr_per_img  \u2502 0.00015625                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 scheduler         \u2502 'yoloxwarmcos'                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 no_aug_epochs     \u2502 15                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ema               \u2502 True                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 weight_decay      \u2502 0.0005                                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 momentum          \u2502 0.9                                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 save_history_ckpt \u2502 True                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 exp_name          \u2502 'my_yolox_gender'                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 test_size         \u2502 (640, 640)                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 test_conf         \u2502 0.01                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 nmsthre           \u2502 0.65                                   \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n2025-04-01 03:51:33 | INFO     | yolox.core.trainer:226 - Model Summary: Params: 8.94M, Gflops: 26.76\n2025-04-01 03:51:33 | INFO     | yolox.data.datasets.coco:63 - loading annotations into memory...\n2025-04-01 03:51:33 | INFO     | yolox.data.datasets.coco:63 - Done (t=0.02s)\n2025-04-01 03:51:33 | INFO     | pycocotools.coco:86 - creating index...\n2025-04-01 03:51:33 | INFO     | pycocotools.coco:86 - index created!\n2025-04-01 03:51:34 | INFO     | yolox.core.trainer:245 - init prefetcher, this might take one minute or less...\n2025-04-01 03:51:38 | INFO     | yolox.data.datasets.coco:63 - loading annotations into memory...\n2025-04-01 03:51:38 | INFO     | yolox.data.datasets.coco:63 - Done (t=0.00s)\n2025-04-01 03:51:38 | INFO     | pycocotools.coco:86 - creating index...\n2025-04-01 03:51:38 | INFO     | pycocotools.coco:86 - index created!\n2025-04-01 03:51:38 | INFO     | yolox.core.trainer:284 - Training start...\n2025-04-01 03:51:38 | INFO     | yolox.core.trainer:285 - \nYOLOX(\n  (backbone): YOLOPAFPN(\n    (backbone): CSPDarknet(\n      (stem): Focus(\n        (conv): BaseConv(\n          (conv): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n      )\n      (dark2): Sequential(\n        (0): BaseConv(\n          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (1): CSPLayer(\n          (conv1): BaseConv(\n            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (conv2): BaseConv(\n            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (conv3): BaseConv(\n            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (m): Sequential(\n            (0): Bottleneck(\n              (conv1): BaseConv(\n                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n                (act): SiLU(inplace=True)\n              )\n              (conv2): BaseConv(\n                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n                (act): SiLU(inplace=True)\n              )\n            )\n          )\n        )\n      )\n      (dark3): Sequential(\n        (0): BaseConv(\n          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (1): CSPLayer(\n          (conv1): BaseConv(\n            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (conv2): BaseConv(\n            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (conv3): BaseConv(\n            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (m): Sequential(\n            (0): Bottleneck(\n              (conv1): BaseConv(\n                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n                (act): SiLU(inplace=True)\n              )\n              (conv2): BaseConv(\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n                (act): SiLU(inplace=True)\n              )\n            )\n            (1): Bottleneck(\n              (conv1): BaseConv(\n                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n                (act): SiLU(inplace=True)\n              )\n              (conv2): BaseConv(\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n                (act): SiLU(inplace=True)\n              )\n            )\n            (2): Bottleneck(\n              (conv1): BaseConv(\n                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n                (act): SiLU(inplace=True)\n              )\n              (conv2): BaseConv(\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n                (act): SiLU(inplace=True)\n              )\n            )\n          )\n        )\n      )\n      (dark4): Sequential(\n        (0): BaseConv(\n          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (1): CSPLayer(\n          (conv1): BaseConv(\n            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (conv2): BaseConv(\n            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (conv3): BaseConv(\n            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (m): Sequential(\n            (0): Bottleneck(\n              (conv1): BaseConv(\n                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n                (act): SiLU(inplace=True)\n              )\n              (conv2): BaseConv(\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n                (act): SiLU(inplace=True)\n              )\n            )\n            (1): Bottleneck(\n              (conv1): BaseConv(\n                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n                (act): SiLU(inplace=True)\n              )\n              (conv2): BaseConv(\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n                (act): SiLU(inplace=True)\n              )\n            )\n            (2): Bottleneck(\n              (conv1): BaseConv(\n                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n                (act): SiLU(inplace=True)\n              )\n              (conv2): BaseConv(\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n                (act): SiLU(inplace=True)\n              )\n            )\n          )\n        )\n      )\n      (dark5): Sequential(\n        (0): BaseConv(\n          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (1): SPPBottleneck(\n          (conv1): BaseConv(\n            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (m): ModuleList(\n            (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n            (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n            (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n          )\n          (conv2): BaseConv(\n            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n        )\n        (2): CSPLayer(\n          (conv1): BaseConv(\n            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (conv2): BaseConv(\n            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (conv3): BaseConv(\n            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (m): Sequential(\n            (0): Bottleneck(\n              (conv1): BaseConv(\n                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n                (act): SiLU(inplace=True)\n              )\n              (conv2): BaseConv(\n                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n                (act): SiLU(inplace=True)\n              )\n            )\n          )\n        )\n      )\n    )\n    (upsample): Upsample(scale_factor=2.0, mode='nearest')\n    (lateral_conv0): BaseConv(\n      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU(inplace=True)\n    )\n    (C3_p4): CSPLayer(\n      (conv1): BaseConv(\n        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (conv2): BaseConv(\n        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (conv3): BaseConv(\n        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): Sequential(\n        (0): Bottleneck(\n          (conv1): BaseConv(\n            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (conv2): BaseConv(\n            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (reduce_conv1): BaseConv(\n      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU(inplace=True)\n    )\n    (C3_p3): CSPLayer(\n      (conv1): BaseConv(\n        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (conv2): BaseConv(\n        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (conv3): BaseConv(\n        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): Sequential(\n        (0): Bottleneck(\n          (conv1): BaseConv(\n            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (conv2): BaseConv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (bu_conv2): BaseConv(\n      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU(inplace=True)\n    )\n    (C3_n3): CSPLayer(\n      (conv1): BaseConv(\n        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (conv2): BaseConv(\n        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (conv3): BaseConv(\n        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): Sequential(\n        (0): Bottleneck(\n          (conv1): BaseConv(\n            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (conv2): BaseConv(\n            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (bu_conv1): BaseConv(\n      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n      (act): SiLU(inplace=True)\n    )\n    (C3_n4): CSPLayer(\n      (conv1): BaseConv(\n        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (conv2): BaseConv(\n        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (conv3): BaseConv(\n        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (m): Sequential(\n        (0): Bottleneck(\n          (conv1): BaseConv(\n            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n          (conv2): BaseConv(\n            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n  )\n  (head): YOLOXHead(\n    (cls_convs): ModuleList(\n      (0-2): 3 x Sequential(\n        (0): BaseConv(\n          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (1): BaseConv(\n          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n      )\n    )\n    (reg_convs): ModuleList(\n      (0-2): 3 x Sequential(\n        (0): BaseConv(\n          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (1): BaseConv(\n          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n      )\n    )\n    (cls_preds): ModuleList(\n      (0-2): 3 x Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (reg_preds): ModuleList(\n      (0-2): 3 x Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (obj_preds): ModuleList(\n      (0-2): 3 x Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (stems): ModuleList(\n      (0): BaseConv(\n        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (1): BaseConv(\n        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (2): BaseConv(\n        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n    )\n    (l1_loss): L1Loss()\n    (bcewithlog_loss): BCEWithLogitsLoss()\n    (iou_loss): IOUloss()\n  )\n)\n2025-04-01 03:51:38 | INFO     | yolox.core.trainer:347 - ---> start train epoch1\n2025-04-01 03:51:47 | INFO     | yolox.core.trainer:399 - epoch: 1/300, iter: 10/28, gpu mem: 14001Mb, mem: 198.7Gb, iter_time: 0.866s, data_time: 0.007s, total_loss: 24.7, iou_loss: 4.5, l1_loss: 0.0, conf_loss: 18.9, cls_loss: 1.3, lr: 5.102e-05, size: 640, ETA: 2:01:03\n2025-04-01 03:51:56 | INFO     | yolox.core.trainer:399 - epoch: 1/300, iter: 20/28, gpu mem: 19997Mb, mem: 194.0Gb, iter_time: 0.889s, data_time: 0.005s, total_loss: 29.8, iou_loss: 4.6, l1_loss: 0.0, conf_loss: 24.0, cls_loss: 1.2, lr: 2.041e-04, size: 800, ETA: 2:02:31\n2025-04-01 03:52:04 | INFO     | yolox.core.trainer:669 - Save weights to ./YOLOX_outputs/my_yolox_gender\n2025-04-01 03:52:04 | INFO     | yolox.core.trainer:691 - Updated state with new checkpoint: ./YOLOX_outputs/my_yolox_gender/latest\n/orange/ufdatastudios/chenz1/TBtest/YOLOX/yolox/core/trainer.py:180: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=self.amp_training):\n/orange/ufdatastudios/chenz1/TBtest/YOLOX/yolox/models/yolo_head.py:474: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=False):\n/orange/ufdatastudios/chenz1/TBtest/YOLOX/yolox/core/trainer.py:200: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.no_grad(), torch.cuda.amp.autocast(enabled=self.amp_training):\n\n  0%|          | 0/7 [00:00<?, ?it/s]\n 14%|#4        | 1/7 [00:03<00:21,  3.54s/it]\n 29%|##8       | 2/7 [00:03<00:07,  1.52s/it]\n 57%|#####7    | 4/7 [00:03<00:01,  1.59it/s]\n 86%|########5 | 6/7 [00:04<00:00,  2.65it/s]\n100%|##########| 7/7 [00:04<00:00,  1.94it/s]\n100%|##########| 7/7 [00:05<00:00,  1.39it/s]2025-04-01 03:52:09 | INFO     | yolox.evaluators.coco_evaluator:261 - Evaluate in main process...\n2025-04-01 03:52:09 | INFO     | yolox.core.trainer:648 - Average forward time: 6.75 ms, Average NMS time: 0.21 ms, Average inference time: 6.96 ms\n\n2025-04-01 03:52:09 | INFO     | yolox.core.trainer:669 - Save weights to ./YOLOX_outputs/my_yolox_gender\n2025-04-01 03:52:09 | INFO     | yolox.core.trainer:691 - Updated state with new checkpoint: ./YOLOX_outputs/my_yolox_gender/last_epoch\n2025-04-01 03:52:09 | INFO     | yolox.core.trainer:669 - Save weights to ./YOLOX_outputs/my_yolox_gender\n2025-04-01 03:52:09 | INFO     | yolox.core.trainer:691 - Updated state with new checkpoint: ./YOLOX_outputs/my_yolox_gender/epoch_1\n2025-04-01 03:52:09 | INFO     | yolox.core.trainer:347 - ---> start train epoch2\n2025-04-01 03:52:15 | INFO     | yolox.core.trainer:399 - epoch: 2/300, iter: 10/28, gpu mem: 19997Mb, mem: 195.9Gb, iter_time: 0.595s, data_time: 0.003s, total_loss: 13.4, iou_loss: 4.4, l1_loss: 0.0, conf_loss: 7.6, cls_loss: 1.4, lr: 7.367e-04, size: 512, ETA: 1:54:19\n2025-04-01 03:52:23 | INFO     | yolox.core.trainer:399 - epoch: 2/300, iter: 20/28, gpu mem: 19997Mb, mem: 198.8Gb, iter_time: 0.814s, data_time: 0.278s, total_loss: 14.0, iou_loss: 4.3, l1_loss: 0.0, conf_loss: 8.3, cls_loss: 1.4, lr: 1.176e-03, size: 736, ETA: 1:54:00\n2025-04-01 03:52:29 | INFO     | yolox.core.trainer:669 - Save weights to ./YOLOX_outputs/my_yolox_gender\n2025-04-01 03:52:30 | INFO     | yolox.core.trainer:691 - Updated state with new checkpoint: ./YOLOX_outputs/my_yolox_gender/latest\n\n/orange/ufdatastudios/chenz1/TBtest/YOLOX/yolox/evaluators/coco_evaluator.py:191: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n  statistics = torch.cuda.FloatTensor([inference_time, nms_time, n_samples])\n\n  0%|          | 0/7 [00:00<?, ?it/s]\n 14%|#4        | 1/7 [00:01<00:09,  1.57s/it]\n 43%|####2     | 3/7 [00:01<00:01,  2.13it/s]\n 71%|#######1  | 5/7 [00:02<00:00,  2.85it/s]\n100%|##########| 7/7 [00:02<00:00,  4.22it/s]\n100%|##########| 7/7 [00:02<00:00,  2.88it/s]2025-04-01 03:52:32 | INFO     | yolox.evaluators.coco_evaluator:261 - Evaluate in main process...\n2025-04-01 03:52:32 | INFO     | yolox.core.trainer:648 - Average forward time: 0.90 ms, Average NMS time: 0.18 ms, Average inference time: 1.08 ms\n\n2025-04-01 03:52:32 | INFO     | yolox.core.trainer:669 - Save weights to ./YOLOX_outputs/my_yolox_gender\n2025-04-01 03:52:32 | INFO     | yolox.core.trainer:691 - Updated state with new checkpoint: ./YOLOX_outputs/my_yolox_gender/last_epoch\n2025-04-01 03:52:32 | INFO     | yolox.core.trainer:669 - Save weights to ./YOLOX_outputs/my_yolox_gender\n2025-04-01 03:52:32 | INFO     | yolox.core.trainer:691 - Updated state with new checkpoint: ./YOLOX_outputs/my_yolox_gender/epoch_2\n2025-04-01 03:52:32 | INFO     | yolox.core.trainer:347 - ---> start train epoch3\n2025-04-01 03:52:41 | INFO     | yolox.core.trainer:399 - epoch: 3/300, iter: 10/28, gpu mem: 19997Mb, mem: 196.4Gb, iter_time: 0.863s, data_time: 0.003s, total_loss: 12.5, iou_loss: 4.1, l1_loss: 0.0, conf_loss: 7.1, cls_loss: 1.4, lr: 2.222e-03, size: 768, ETA: 1:53:51\n2025-04-01 03:52:47 | INFO     | yolox.core.trainer:399 - epoch: 3/300, iter: 20/28, gpu mem: 19997Mb, mem: 198.7Gb, iter_time: 0.614s, data_time: 0.039s, total_loss: 12.2, iou_loss: 3.8, l1_loss: 0.0, conf_loss: 6.9, cls_loss: 1.5, lr: 2.947e-03, size: 768, ETA: 1:49:58\n2025-04-01 03:52:54 | INFO     | yolox.core.trainer:669 - Save weights to ./YOLOX_outputs/my_yolox_gender\n2025-04-01 03:52:55 | INFO     | yolox.core.trainer:691 - Updated state with new checkpoint: ./YOLOX_outputs/my_yolox_gender/latest\n\n\n  0%|          | 0/7 [00:00<?, ?it/s]\n 14%|#4        | 1/7 [00:01<00:09,  1.66s/it]\n 43%|####2     | 3/7 [00:01<00:01,  2.00it/s]\n 71%|#######1  | 5/7 [00:02<00:00,  2.91it/s]\n100%|##########| 7/7 [00:02<00:00,  4.30it/s]\n100%|##########| 7/7 [00:02<00:00,  2.86it/s]2025-04-01 03:52:57 | INFO     | yolox.evaluators.coco_evaluator:261 - Evaluate in main process...\n2025-04-01 03:52:57 | INFO     | yolox.core.trainer:648 - Average forward time: 0.91 ms, Average NMS time: 0.20 ms, Average inference time: 1.11 ms\n\n2025-04-01 03:52:57 | INFO     | yolox.core.trainer:669 - Save weights to ./YOLOX_outputs/my_yolox_gender\n2025-04-01 03:52:57 | INFO     | yolox.core.trainer:691 - Updated state with new checkpoint: ./YOLOX_outputs/my_yolox_gender/last_epoch\n2025-04-01 03:52:57 | INFO     | yolox.core.trainer:669 - Save weights to ./YOLOX_outputs/my_yolox_gender\n2025-04-01 03:52:57 | INFO     | yolox.core.trainer:691 - Updated state with new checkpoint: ./YOLOX_outputs/my_yolox_gender/epoch_3\n2025-04-01 03:52:57 | INFO     | yolox.core.trainer:347 - ---> start train epoch4\n2025-04-01 03:53:04 | INFO     | yolox.core.trainer:399 - epoch: 4/300, iter: 10/28, gpu mem: 19997Mb, mem: 198.6Gb, iter_time: 0.666s, data_time: 0.008s, total_loss: 10.5, iou_loss: 3.8, l1_loss: 0.0, conf_loss: 5.5, cls_loss: 1.2, lr: 4.508e-03, size: 480, ETA: 1:49:06\n2025-04-01 03:53:12 | INFO     | yolox.core.trainer:399 - epoch: 4/300, iter: 20/28, gpu mem: 19997Mb, mem: 198.7Gb, iter_time: 0.814s, data_time: 0.361s, total_loss: 10.8, iou_loss: 3.4, l1_loss: 0.0, conf_loss: 6.1, cls_loss: 1.3, lr: 5.518e-03, size: 768, ETA: 1:49:18\n2025-04-01 03:53:18 | INFO     | yolox.core.trainer:669 - Save weights to ./YOLOX_outputs/my_yolox_gender\n2025-04-01 03:53:19 | INFO     | yolox.core.trainer:691 - Updated state with new checkpoint: ./YOLOX_outputs/my_yolox_gender/latest\n\n\n  0%|          | 0/7 [00:00<?, ?it/s]\n 14%|#4        | 1/7 [00:01<00:08,  1.41s/it]\n 29%|##8       | 2/7 [00:01<00:03,  1.45it/s]\n 43%|####2     | 3/7 [00:01<00:01,  2.14it/s]\n 71%|#######1  | 5/7 [00:02<00:00,  2.73it/s]\n100%|##########| 7/7 [00:02<00:00,  4.18it/s]\n100%|##########| 7/7 [00:02<00:00,  2.67it/s]2025-04-01 03:53:21 | INFO     | yolox.evaluators.coco_evaluator:261 - Evaluate in main process...\n2025-04-01 03:53:21 | INFO     | yolox.evaluators.coco_evaluator:294 - Loading and preparing results...\n2025-04-01 03:53:21 | INFO     | yolox.evaluators.coco_evaluator:294 - DONE (t=0.00s)\n2025-04-01 03:53:21 | INFO     | pycocotools.coco:366 - creating index...\n2025-04-01 03:53:21 | INFO     | pycocotools.coco:366 - index created!\n2025-04-01 03:53:21 | ERROR    | yolox.core.trainer:141 - Exception in training: \n2025-04-01 03:53:21 | INFO     | yolox.core.trainer:288 - Training of experiment is done and the best AP is 0.00\n2025-04-01 03:53:21 | ERROR    | yolox.core.launch:98 - An error has been caught in function 'launch', process 'MainProcess' (1244981), thread 'MainThread' (22709608871744):\nTraceback (most recent call last):\n\n  File \"/home/chenz1/toorange/TBtest/YOLOX/tools/train.py\", line 138, in <module>\n    launch(\n    \u2514 <function launch at 0x14a6acd8b9a0>\n\n> File \"/orange/ufdatastudios/chenz1/TBtest/YOLOX/yolox/core/launch.py\", line 98, in launch\n    main_func(*args)\n    \u2502          \u2514 (\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550...\n    \u2514 <function main at 0x14a64b545480>\n\n  File \"/home/chenz1/toorange/TBtest/YOLOX/tools/train.py\", line 118, in main\n    trainer.train()\n    \u2502       \u2514 <function Trainer.train at 0x14a64b5455a0>\n    \u2514 <yolox.core.trainer.Trainer object at 0x14a6925e2020>\n\n  File \"/orange/ufdatastudios/chenz1/TBtest/YOLOX/yolox/core/trainer.py\", line 139, in train\n    self.train_in_epoch()\n    \u2502    \u2514 <function Trainer.train_in_epoch at 0x14a64b545630>\n    \u2514 <yolox.core.trainer.Trainer object at 0x14a6925e2020>\n\n  File \"/orange/ufdatastudios/chenz1/TBtest/YOLOX/yolox/core/trainer.py\", line 162, in train_in_epoch\n    self.after_epoch()\n    \u2502    \u2514 <function Trainer.after_epoch at 0x14a64b545990>\n    \u2514 <yolox.core.trainer.Trainer object at 0x14a6925e2020>\n\n  File \"/orange/ufdatastudios/chenz1/TBtest/YOLOX/yolox/core/trainer.py\", line 366, in after_epoch\n    self.evaluate_and_save_model()\n    \u2502    \u2514 <function Trainer.evaluate_and_save_model at 0x14a64b545c60>\n    \u2514 <yolox.core.trainer.Trainer object at 0x14a6925e2020>\n\n  File \"/orange/ufdatastudios/chenz1/TBtest/YOLOX/yolox/core/trainer.py\", line 617, in evaluate_and_save_model\n    bias_amps = [abs(pred_counts[cls_name] / total_pred / (gt_counts[cls_name] / total_gt) - 1)\n                     \u2502           \u2502           \u2502             \u2502         \u2502           \u2514 1218\n                     \u2502           \u2502           \u2502             \u2502         \u2514 'female'\n                     \u2502           \u2502           \u2502             \u2514 {'male': 695, 'female': 523}\n                     \u2502           \u2502           \u2514 0\n                     \u2502           \u2514 'female'\n                     \u2514 {'male': 0, 'female': 0}\n\n  File \"/orange/ufdatastudios/chenz1/TBtest/YOLOX/yolox/core/trainer.py\", line 617, in <listcomp>\n    bias_amps = [abs(pred_counts[cls_name] / total_pred / (gt_counts[cls_name] / total_gt) - 1)\n                     \u2502           \u2502           \u2502             \u2502         \u2502           \u2514 1218\n                     \u2502           \u2502           \u2502             \u2502         \u2514 'male'\n                     \u2502           \u2502           \u2502             \u2514 {'male': 695, 'female': 523}\n                     \u2502           \u2502           \u2514 0\n                     \u2502           \u2514 'male'\n                     \u2514 {'male': 0, 'female': 0}\n\nZeroDivisionError: division by zero\n\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nCOCOeval_opt.evaluate() finished in 0.03 seconds.\nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished in 0.00 seconds.\n\nTraining stopped.\n",
  "running": false,
  "iteration": 20,
  "learning_rate_adaptive": 0.01,
  "progress": "epoch: 4/300, iter: 20/28",
  "mem": "gpu mem: 19997Mb, mem: 198.7Gb",
  "time": "iter_time: 0.814s, data_time: 0.361s",
  "eta": "ETA: 1:49:18",
  "last_checkpoint": "./YOLOX_outputs/my_yolox_gender/latest"
}